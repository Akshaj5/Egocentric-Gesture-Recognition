{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# compute IDFT features\n",
    "\n",
    "import subprocess, os\n",
    "\n",
    "def assure_path_exists(path):\n",
    "    #make dir if doesnt exist\n",
    "        dir = os.path.dirname(path)\n",
    "        if not os.path.exists(dir):\n",
    "                os.makedirs(dir)\n",
    "\n",
    "#Path to videos with trailing slash\n",
    "videosPath=\"/home/anuj/gestures/handseg_museum/\"\n",
    "\n",
    "subject_list=[name for name in os.listdir(videosPath)]\n",
    "gesture_list=[name for name in os.listdir(videosPath+subject_list[0])]\n",
    "\n",
    "#Path to Dense trajectories binary\n",
    "dtbin=\"/home/anuj/dense_trajectory_release_v1.2/release/DenseTrack\"\n",
    "\n",
    "#Path where the DT features need to be stored, with trailing slash\n",
    "DTPath=\"/home/anuj/gestures/handseg_features/\"\n",
    "assure_path_exists(DTPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted & Stored DT features of Video  /home/anuj/gestures/handseg_museum/subject_1/take_a_picture/take_a_picture_01.avi\n",
      "Extracted & Stored DT features of Video  /home/anuj/gestures/handseg_museum/subject_1/take_a_picture/take_a_picture_04.avi\n",
      "Extracted & Stored DT features of Video  /home/anuj/gestures/handseg_museum/subject_1/take_a_picture/take_a_picture_05.avi\n",
      "Extracted & Stored DT features of Video  /home/anuj/gestures/handseg_museum/subject_1/take_a_picture/take_a_picture_03.avi\n",
      "Extracted & Stored DT features of Video  /home/anuj/gestures/handseg_museum/subject_1/take_a_picture/take_a_picture_07.avi\n",
      "Extracted & Stored DT features of Video  /home/anuj/gestures/handseg_museum/subject_1/take_a_picture/take_a_picture_06.avi\n",
      "Extracted & Stored DT features of Video  /home/anuj/gestures/handseg_museum/subject_1/like/like_04.avi\n",
      "Extracted & Stored DT features of Video  /home/anuj/gestures/handseg_museum/subject_1/like/like_07.avi\n",
      "Extracted & Stored DT features of Video  /home/anuj/gestures/handseg_museum/subject_1/like/like_03.avi\n",
      "Extracted & Stored DT features of Video  /home/anuj/gestures/handseg_museum/subject_1/like/like_05.avi\n",
      "Extracted & Stored DT features of Video  /home/anuj/gestures/handseg_museum/subject_1/like/like_06.avi\n",
      "Extracted & Stored DT features of Video  /home/anuj/gestures/handseg_museum/subject_1/like/like_01.avi\n",
      "Extracted & Stored DT features of Video  /home/anuj/gestures/handseg_museum/subject_2/take_a_picture/take_a_picture_01.avi\n",
      "Extracted & Stored DT features of Video  /home/anuj/gestures/handseg_museum/subject_2/take_a_picture/take_a_picture_04.avi\n",
      "Extracted & Stored DT features of Video  /home/anuj/gestures/handseg_museum/subject_2/take_a_picture/take_a_picture_02.avi\n",
      "Extracted & Stored DT features of Video  /home/anuj/gestures/handseg_museum/subject_2/take_a_picture/take_a_picture_05.avi\n",
      "Extracted & Stored DT features of Video  /home/anuj/gestures/handseg_museum/subject_2/take_a_picture/take_a_picture_03.avi\n",
      "Extracted & Stored DT features of Video  /home/anuj/gestures/handseg_museum/subject_2/take_a_picture/take_a_picture_07.avi\n",
      "Extracted & Stored DT features of Video  /home/anuj/gestures/handseg_museum/subject_2/take_a_picture/take_a_picture_06.avi\n",
      "Extracted & Stored DT features of Video  /home/anuj/gestures/handseg_museum/subject_2/like/like_04.avi\n",
      "Extracted & Stored DT features of Video  /home/anuj/gestures/handseg_museum/subject_2/like/like_03.avi\n",
      "Extracted & Stored DT features of Video  /home/anuj/gestures/handseg_museum/subject_2/like/like_05.avi\n",
      "Extracted & Stored DT features of Video  /home/anuj/gestures/handseg_museum/subject_2/like/like_02.avi\n",
      "Extracted & Stored DT features of Video  /home/anuj/gestures/handseg_museum/subject_2/like/like_06.avi\n",
      "Extracted & Stored DT features of Video  /home/anuj/gestures/handseg_museum/subject_2/like/like_01.avi\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Iterate over gesture videos one by one\n",
    "# using trajectory length 10 since some gestures have very short trajectories and spaces in under 11-15frame\n",
    "for subject in subject_list:\n",
    "    for gesturename in gesture_list:\n",
    "        vp=videosPath+subject+\"/\"+gesturename + \"/\"\n",
    "        fp=DTPath+subject+\"/\"+gesturename + \"/\"\n",
    "        assure_path_exists(fp)\n",
    "        for name in os.listdir(vp): \n",
    "                subprocess.call('%s %s -L 8 > %s' % (dtbin,vp+name, fp+name[:-4]+\".txt\"), shell=True)\n",
    "                print (\"Extracted & Stored DT features of Video \", vp+name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read from files and create feature wise vetors..\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "TRAJ_DIM=30\n",
    "HOG_DIM=96\n",
    "HOF_DIM=108\n",
    "MBHX_DIM=96\n",
    "MBHY_DIM=96\n",
    "\n",
    "\n",
    "totalvids=27\n",
    "gesture1=2\n",
    "\n",
    "traj_start =10\n",
    "hog_start = traj_start + TRAJ_DIM\n",
    "hof_start = hog_start + HOG_DIM\n",
    "mbhx_start = hof_start + HOF_DIM\n",
    "mbhy_start = mbhx_start + MBHX_DIM\n",
    "mbhy_end = mbhy_start + MBHY_DIM\n",
    "\n",
    "# Parses a video's IDTF file and returns a list of IDTF of that video\n",
    "def extract_IDTF(vname):\n",
    "    lines = []\n",
    "    with open(vname) as f:\n",
    "         lines= f.readlines()\n",
    "    \n",
    "    trajs=[]\n",
    "    hogs=[]\n",
    "    hofs=[]\n",
    "    mbhxs=[]\n",
    "    mbhys=[]\n",
    "    \n",
    "    for line in lines:\n",
    "        ll = line.strip().split()\n",
    "        traj = [float(l) for l in ll[traj_start:hog_start]]\n",
    "        hog = [float(l) for l in ll[hog_start:hof_start]]\n",
    "        hof = [float(l) for l in ll[hof_start:mbhx_start]]\n",
    "        mbhx = [float(l) for l in ll[mbhx_start:mbhy_start]]\n",
    "        mbhy = [float(l) for l in ll[mbhy_start:mbhy_end]]\n",
    "    \n",
    "        \n",
    "        trajs.append(np.array(traj))\n",
    "        hogs.append(np.array(hog))\n",
    "        hofs.append(np.array(hof))\n",
    "        mbhxs.append(np.array(mbhx))\n",
    "        mbhys.append(np.array(mbhy))\n",
    "    print (vname,\"lines\", len(lines))    \n",
    "    return (trajs,hogs,hofs,mbhxs,mbhys)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject_1\n",
      "['take_a_picture_04.txt' 'take_a_picture_07.txt' 'take_a_picture_06.txt'\n",
      " 'take_a_picture_01.txt']\n",
      "['like_01.txt' 'like_07.txt' 'like_04.txt' 'like_03.txt']\n",
      "subject_2\n",
      "['take_a_picture_07.txt' 'take_a_picture_01.txt' 'take_a_picture_05.txt'\n",
      " 'take_a_picture_04.txt' 'take_a_picture_02.txt']\n",
      "['like_04.txt' 'like_01.txt' 'like_06.txt' 'like_03.txt']\n",
      "Sampling the foll vids for generating codebooks...\n",
      "/home/anuj/gestures/handseg_features/subject_1/take_a_picture/take_a_picture_04.txt lines 5347\n",
      "0\n",
      "/home/anuj/gestures/handseg_features/subject_1/take_a_picture/take_a_picture_07.txt lines 3591\n",
      "1\n",
      "/home/anuj/gestures/handseg_features/subject_1/take_a_picture/take_a_picture_06.txt lines 6531\n",
      "2\n",
      "/home/anuj/gestures/handseg_features/subject_1/take_a_picture/take_a_picture_01.txt lines 4026\n",
      "3\n",
      "/home/anuj/gestures/handseg_features/subject_1/like/like_01.txt lines 600\n",
      "4\n",
      "/home/anuj/gestures/handseg_features/subject_1/like/like_07.txt lines 2438\n",
      "5\n",
      "/home/anuj/gestures/handseg_features/subject_1/like/like_04.txt lines 2424\n",
      "6\n",
      "/home/anuj/gestures/handseg_features/subject_1/like/like_03.txt lines 1816\n",
      "7\n",
      "/home/anuj/gestures/handseg_features/subject_2/take_a_picture/take_a_picture_07.txt lines 2308\n",
      "8\n",
      "/home/anuj/gestures/handseg_features/subject_2/take_a_picture/take_a_picture_01.txt lines 1817\n",
      "9\n",
      "/home/anuj/gestures/handseg_features/subject_2/take_a_picture/take_a_picture_05.txt lines 2052\n",
      "10\n",
      "/home/anuj/gestures/handseg_features/subject_2/take_a_picture/take_a_picture_04.txt lines 1772\n",
      "11\n",
      "/home/anuj/gestures/handseg_features/subject_2/take_a_picture/take_a_picture_02.txt lines 1812\n",
      "12\n",
      "/home/anuj/gestures/handseg_features/subject_2/like/like_04.txt lines 721\n",
      "13\n",
      "/home/anuj/gestures/handseg_features/subject_2/like/like_01.txt lines 600\n",
      "14\n",
      "/home/anuj/gestures/handseg_features/subject_2/like/like_06.txt lines 841\n",
      "15\n",
      "/home/anuj/gestures/handseg_features/subject_2/like/like_03.txt lines 965\n",
      "16\n",
      "39661\n"
     ]
    }
   ],
   "source": [
    "\n",
    "alltrajs=[]\n",
    "allhogs=[]\n",
    "allhofs=[]\n",
    "allmbhxs=[]\n",
    "allmbhys=[]\n",
    "labels=[]\n",
    "\n",
    "videoFeatures=[]\n",
    "\n",
    "#Iterate over videos\n",
    "allvids=[]\n",
    "labels=[]\n",
    "l=0\n",
    "sampled_vids=[]\n",
    "\n",
    "for subject in subject_list:\n",
    "    print (subject)\n",
    "    l=0\n",
    "    for gesturename in gesture_list:\n",
    "        #print (gesturename)\n",
    "        videos_under_gesture=os.listdir(DTPath+subject+\"/\"+gesturename)\n",
    "#         print (videos_under_gesture)\n",
    "        #chose 30% of all vids randomly to generate codebooks\n",
    "        sampled_vid_gest=np.random.choice(videos_under_gesture,int(len(videos_under_gesture)*0.80) , replace=False)\n",
    "        labels+=[l]*len(videos_under_gesture)\n",
    "        sampled_vids+=[DTPath+subject+\"/\"+gesturename+\"/\"+vname for vname in sampled_vid_gest.tolist()]\n",
    "        \n",
    "        print (sampled_vid_gest)\n",
    "        #print (sampled_vids)\n",
    "        allvids+=[DTPath+subject+\"/\"+gesturename+\"/\"+vname for vname in videos_under_gesture]\n",
    "        l+=1\n",
    "\n",
    "print (\"Sampling the foll vids for generating codebooks...\")\n",
    "for v in range(len(sampled_vids)):\n",
    "    traj,hog,hof,mbhx,mbhy=extract_IDTF(sampled_vids[v])\n",
    "    alltrajs+=traj\n",
    "    allhogs+=hog\n",
    "    allhofs+=hof\n",
    "    allmbhxs+=mbhx\n",
    "    allmbhys+=mbhy\n",
    "    print (v)\n",
    "print (len(alltrajs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#just to tally labelling\n",
    "g=2\n",
    "for vid, label in zip(allvids,labels):\n",
    "    if label==g:\n",
    "        print (gesture_list[g],vid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "alltrajs = np.array(alltrajs)\n",
    "allhogs = np.array(allhogs)\n",
    "allhofs = np.array(allhofs)\n",
    "allmbhxs = np.array(allmbhxs)\n",
    "allmbhys = np.array(allmbhys)\n",
    "labels=np.array(labels)\n",
    "\n",
    "# print (alltrajs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels=labels.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.cluster.vq import vq, kmeans, whiten\n",
    "from sklearn import *\n",
    "from numpy import vstack,array\n",
    "from numpy.random import rand\n",
    "from scipy.cluster.vq import kmeans,vq\n",
    "\n",
    "# Perform k-means clustering & generate codebooks\n",
    "k=500\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "traj_code_book, variance = kmeans(alltrajs, k)\n",
    "hogs_code_book, variance = kmeans(allhogs, k)\n",
    "hofs_code_book, variance = kmeans(allhofs, k)\n",
    "mbhxs_code_book, variance = kmeans(allmbhxs, k)\n",
    "mbhys_code_book, variance = kmeans(allmbhys, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "codebook=[traj_code_book,hogs_code_book,hofs_code_book,mbhxs_code_book,mbhys_code_book]\n",
    "\n",
    "def powernorm(hist):\n",
    "     hist = np.sign(hist) * (np.abs(hist) ** 0.5)\n",
    "     return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Calculate of BOW per Video\n",
    "#input IDFT of Video [(X,96), (X,100), (X,96), (X,100)]\n",
    "#output np.array([(500,1),(500,1),(500,1),(500,1),(500,1)])\n",
    "def computeBOW(videoFeat):\n",
    "    BOW=[]\n",
    "    print (\"video feat len\",len(videoFeat))\n",
    "    for descrip,cbook in zip(videoFeat,codebook):\n",
    "        #descrip (X,dim), #cbook(500,dim)\n",
    "        hist,dist=vq(descrip,cbook)\n",
    "        histo,bins= np.histogram(hist,np.arange(500), density=True)\n",
    "        BOW.append(powernorm(histo))\n",
    "    BOW=np.array(BOW)\n",
    "    print (\"BOW\", BOW.shape)\n",
    "    return BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1]\n",
      "/home/anuj/gestures/handseg_features/subject_1/take_a_picture/take_a_picture_05.txt lines 3401\n",
      "video feat len 5\n",
      "BOW (5, 499)\n",
      "/home/anuj/gestures/handseg_features/subject_1/take_a_picture/take_a_picture_07.txt lines 3591\n",
      "video feat len 5\n",
      "BOW (5, 499)\n",
      "/home/anuj/gestures/handseg_features/subject_1/take_a_picture/take_a_picture_06.txt lines 6531\n",
      "video feat len 5\n",
      "BOW (5, 499)\n",
      "/home/anuj/gestures/handseg_features/subject_1/take_a_picture/take_a_picture_04.txt lines 5347\n",
      "video feat len 5\n",
      "BOW (5, 499)\n",
      "/home/anuj/gestures/handseg_features/subject_1/take_a_picture/take_a_picture_03.txt lines 4542\n",
      "video feat len 5\n",
      "BOW (5, 499)\n",
      "/home/anuj/gestures/handseg_features/subject_1/take_a_picture/take_a_picture_01.txt lines 4026\n",
      "video feat len 5\n",
      "BOW (5, 499)\n",
      "/home/anuj/gestures/handseg_features/subject_1/like/like_07.txt lines 2438\n",
      "video feat len 5\n",
      "BOW (5, 499)\n",
      "/home/anuj/gestures/handseg_features/subject_1/like/like_01.txt lines 600\n",
      "video feat len 5\n",
      "BOW (5, 499)\n",
      "/home/anuj/gestures/handseg_features/subject_1/like/like_04.txt lines 2424\n",
      "video feat len 5\n",
      "BOW (5, 499)\n",
      "/home/anuj/gestures/handseg_features/subject_1/like/like_03.txt lines 1816\n",
      "video feat len 5\n",
      "BOW (5, 499)\n",
      "/home/anuj/gestures/handseg_features/subject_1/like/like_05.txt lines 934\n",
      "video feat len 5\n",
      "BOW (5, 499)\n",
      "/home/anuj/gestures/handseg_features/subject_1/like/like_06.txt lines 1894\n",
      "video feat len 5\n",
      "BOW (5, 499)\n",
      "/home/anuj/gestures/handseg_features/subject_2/take_a_picture/take_a_picture_05.txt lines 2052\n",
      "video feat len 5\n",
      "BOW (5, 499)\n",
      "/home/anuj/gestures/handseg_features/subject_2/take_a_picture/take_a_picture_07.txt lines 2308\n",
      "video feat len 5\n",
      "BOW (5, 499)\n",
      "/home/anuj/gestures/handseg_features/subject_2/take_a_picture/take_a_picture_06.txt lines 2364\n",
      "video feat len 5\n",
      "BOW (5, 499)\n",
      "/home/anuj/gestures/handseg_features/subject_2/take_a_picture/take_a_picture_04.txt lines 1772\n",
      "video feat len 5\n",
      "BOW (5, 499)\n",
      "/home/anuj/gestures/handseg_features/subject_2/take_a_picture/take_a_picture_02.txt lines 1812\n",
      "video feat len 5\n",
      "BOW (5, 499)\n",
      "/home/anuj/gestures/handseg_features/subject_2/take_a_picture/take_a_picture_03.txt lines 2041\n",
      "video feat len 5\n",
      "BOW (5, 499)\n",
      "/home/anuj/gestures/handseg_features/subject_2/take_a_picture/take_a_picture_01.txt lines 1817\n",
      "video feat len 5\n",
      "BOW (5, 499)\n",
      "/home/anuj/gestures/handseg_features/subject_2/like/like_01.txt lines 600\n",
      "video feat len 5\n",
      "BOW (5, 499)\n",
      "/home/anuj/gestures/handseg_features/subject_2/like/like_04.txt lines 721\n",
      "video feat len 5\n",
      "BOW (5, 499)\n",
      "/home/anuj/gestures/handseg_features/subject_2/like/like_03.txt lines 965\n",
      "video feat len 5\n",
      "BOW (5, 499)\n",
      "/home/anuj/gestures/handseg_features/subject_2/like/like_05.txt lines 658\n",
      "video feat len 5\n",
      "BOW (5, 499)\n",
      "/home/anuj/gestures/handseg_features/subject_2/like/like_06.txt lines 841\n",
      "video feat len 5\n",
      "BOW (5, 499)\n",
      "/home/anuj/gestures/handseg_features/subject_2/like/like_02.txt lines 824\n",
      "video feat len 5\n",
      "BOW (5, 499)\n",
      "\n",
      "All Features Shape= (25, 5, 499)\n"
     ]
    }
   ],
   "source": [
    "# make vectors for training\n",
    "\n",
    "features=[] #(numvideos,500, 4)\n",
    "print (labels)\n",
    "for vname in allvids:\n",
    "    videoFeat=extract_IDTF(vname)\n",
    "    features.append(computeBOW(videoFeat))\n",
    "    \n",
    "features=np.array(features)\n",
    "labels=np.array(labels)\n",
    "print (\"\")\n",
    "print (\"All Features Shape=\",(features.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 2495) 5 499\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "#Split into test and train\n",
    "x,des,dims=features.shape\n",
    "features=features.reshape((x,des*dims))\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.5, random_state=7)\n",
    "print (features.shape, des,dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 2495) (13, 2495)\n",
      "linearsvm 1.0\n",
      "Dasd\n"
     ]
    }
   ],
   "source": [
    "# Train the Linear SVM\n",
    "from sklearn.svm import SVC\n",
    "print (X_train.shape, X_test.shape)\n",
    "clf = SVC(kernel='linear').fit(X_train, y_train)\n",
    "print (\"linearsvm\", clf.score(X_test, y_test))\n",
    "print (\"Dasd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-224fe75a31d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Save the SVM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexternals\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mjoblib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcodebook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"classifier500.pkl\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "# Save the SVM\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump((clf,codebook), \"classifier500.pkl\", compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
